% IEEE Paper Template - By Gemini (V3, Further Corrected)
\documentclass[conference]{IEEEtran}

%
% PACKAGES
%
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{microtype}
\usepackage{cite}
\usepackage{booktabs} % For professional-looking tables

% Configure hyperref for IEEE papers
% It's often recommended to load hyperref last
\usepackage[bookmarks=false, hidelinks]{hyperref}

%
% LISTINGS STYLE
%
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  breakatwhitespace=true,
  columns=fullflexible,
  keepspaces=true,
  numbers=left,
  numberstyle=\tiny,
  frame=single,
  framerule=0.5pt,
  rulecolor=\color{black!40},
  backgroundcolor=\color{black!2},
  showstringspaces=false,
  captionpos=b
}

%
% METADATA
%
\title{A Lightweight Deterministic Approach to Localization via Range-Based Odometry Correction}

\author{
    \IEEEauthorblockN{Danish Tapia}
    \IEEEauthorblockA{\textit{MIT Tech Team}\\
    danish.tapia017@gmail.com}
    \and
    \IEEEauthorblockN{Om Gunjal}
    \IEEEauthorblockA{\textit{MIT Tech Team}\\
    om.gunjal@example.com}
}

% This command is used to get the desired BibTeX styles
\bstctlcite{IEEEexample:BSTcontrol}

\begin{document}
\maketitle

%
% CONTENT
%

\begin{abstract}
This paper presents a lightweight, deterministic localization algorithm for mobile robots operating within a known rectangular arena. The proposed method fuses wheel-encoder dead-reckoning and IMU-derived heading with measurements from a sparse set of range sensors to produce real-time pose estimates $(x, y, \theta)$. Localization is achieved by analytically predicting ray-wall intersections, validating measurements with a rule-based filter, and applying direct algebraic corrections to accumulated odometry offsets. This approach avoids the computational overhead of probabilistic filtering or iterative optimization. It is robust to transient occlusions and sensor dropouts, requires minimal arithmetic operations, and is well-suited for resource-constrained microcontrollers. We provide a detailed algorithmic breakdown, complexity analysis, and representative C-style code. A comprehensive experimental plan is proposed to validate the method's performance against standard EKF and particle filter baselines.
\end{abstract}

\begin{IEEEkeywords}
Localization, Range Sensors, Odometry, Sensor Fusion, Embedded Systems, Deterministic Algorithm, Mobile Robotics.
\end{IEEEkeywords}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.9\columnwidth]{SystemOverview.png}
    \caption{System overview showing the robot within the known rectangular arena of width $W$ and length $L$. The world frame $W$ is fixed to the arena, while the robot frame $R$ moves with the robot. The pose $(x, y, \theta)$ defines the transformation from $R$ to $W$.}
    \label{fig:system_overview}
\end{figure}

\section{Introduction}
Reliable self-localization is a cornerstone of mobile robot autonomy. In many structured environments—such as arenas for robotic competitions, standardized warehouse aisles, or designated clean rooms—the robot's workspace is geometrically simple and known \textit{ad priori}. In these contexts, the primary challenge is not mapping, but rather maintaining an accurate pose estimate in the face of actuator and sensor noise, particularly odometric drift.

High-fidelity solutions like Simultaneous Localization and Mapping (SLAM) \cite{probrobot} or Iterative Closest Point (ICP) scan matching \cite{icp} are powerful but often require dense sensor data (e.g., from a LiDAR) and significant computational power, making them unsuitable for low-cost platforms. Probabilistic methods like Monte Carlo Localization (MCL) \cite{mcl} are more flexible but their performance is tied to the number of particles, which directly impacts CPU load.

This creates a distinct need for algorithms that are computationally frugal yet robust enough for real-time control. This is the gap our work addresses. We propose a deterministic localization algorithm that leverages the geometric constraints of a known rectangular environment to directly correct odometry errors. By using a sparse set of range sensors (e.g., time-of-flight or infrared), our method provides axis-by-axis corrections without resorting to complex state estimation.

The main contributions of this work are threefold:
\begin{itemize}
  \item A deterministic, analytic localization pipeline that computes closed-form pose corrections from as few as one valid range measurement.
  \item A robust, rule-based validation filter to handle real-world sensor issues like occlusions, saturation, and geometric ambiguities near corners.
  \item A detailed analysis of the algorithm's computational complexity and a reference implementation, demonstrating its suitability for embedded systems like STM32-class microcontrollers.
\end{itemize}

The paper is structured as follows: Section II reviews related work. Section III defines the system model and problem. Section IV details the proposed methodology. Section V analyzes its complexity. Section VI outlines an evaluation plan, and Section VII concludes with a discussion of limitations and future work.

\section{Related Work}
Localization for mobile robots is a mature and well-established field, largely dominated by probabilistic methods due to their effectiveness in handling sensor noise and environmental uncertainty.

The \textbf{Extended Kalman Filter (EKF)} represents a classic approach, extending the linear Kalman Filter to handle the non-linear dynamics inherent in robot motion \cite{probrobot, Smith1990}. EKFs provide an efficient recursive framework for fusing odometry with external sensor measurements. However, their reliance on first-order linearization of the motion and measurement models can introduce significant errors, potentially leading to filter divergence when non-linearities are pronounced, such as when a robot's sensors view different walls. The assumption of Gaussian noise is also a common limitation.

To address the limitations of linearization, \textbf{Particle Filters}, most notably in the form of \textbf{Monte Carlo Localization (MCL)}, were introduced \cite{mcl, Dellaert1999}. MCL represents the posterior belief of the robot's pose with a set of weighted samples (particles). This non-parametric approach can model arbitrary, multi-modal probability distributions, making it robust to global localization challenges (the "kidnapped robot problem") and highly non-linear systems. The primary drawback of MCL is its computational complexity, which scales directly with the number of particles required to maintain an accurate belief, often rendering it unsuitable for resource-constrained embedded systems.

Parallel to probabilistiadc state estimation, other methods focus on leveraging environmental geometry. \textbf{Iterative Closest Point (ICP)} and its variants are powerful algorithms for aligning dense point clouds from sensors like LiDAR against a known map \cite{icp, Besl1992}. While highly accurate, these methods are computationally intensive and require dense sensor data, precluding their effective use on low-cost platforms with sparse sensors or limited processing capabilities.

The sub-problem of \textbf{range-only localization} has also been studied extensively. Theoretical foundations explore observability conditions with minimal sensing, as established by O'Kane and LaValle \cite{okane}. Many practical solutions rely on iterative non-linear optimization techniques to solve the multilateration problem, sometimes with formal guarantees \cite{rangeopt}. Our work is philosophically similar but trades the generality of these optimization-based approaches for extreme computational efficiency by exploiting the specific geometric constraints of a known rectangular environment to derive direct, analytical corrections. This deterministic approach, designed for resource-constrained embedded systems like STM32-class microcontrollers, operates with minimal computational overhead (O(Ns) complexity) and minimal memory footprint, carving a niche between heavy probabilistic filters and data-hungry scan matching methods.

\section{System Model and Problem Formulation}
\subsection{System Model}
We model the robot as a rigid body moving on a 2D plane.
\begin{itemize}
    \item \textbf{Pose:} The robot's pose in the world frame $W$ is $p = (x, y, \theta)^T$, where $(x, y)$ is the position of the robot's center and $\theta$ is its orientation.
    \item \textbf{Environment:} The environment is a rectangular arena of known dimensions, width $W$ and length $L$, with walls aligned with the world frame axes at $x=0, x=W, y=0, y=L$.
    \item \textbf{Sensors:} The robot is equipped with $N_s$ single-beam range sensors (up to 4 in our reference design). Each sensor $i$ is mounted at a fixed pose $(x_{tf,i}, y_{tf,i}, \phi_i)$ relative to the robot's frame $R$.
    \item \textbf{Motion:} The robot's motion is tracked via wheel encoders, which provide an estimate of the robot's displacement (odometry). An IMU provides an independent measurement of the global heading $\theta$.
\end{itemize}

\subsection{Problem Formulation}
The core problem is to estimate the robot's true pose $p$ by correcting the drift-prone odometry using the sparse range measurements. Each sensor $i$ provides a distance measurement $d_i$. The ideal measurement model is:
\[
    d_i = h_i(p) + \epsilon_i
\]
where $h_i(p)$ is the true distance from the sensor to the nearest wall along its measurement axis, and $\epsilon_i$ is zero-mean Gaussian noise. Our goal is to compute a corrective offset $(\delta_x, \delta_y)$ to the odometry-based pose estimate at a rate sufficient for real-time control.

\section{Proposed Methodology}
\subsection{Algorithmic Pipeline}
The algorithm is executed in a loop, typically synchronized with the arrival of new sensor data.
\begin{enumerate}
  \item \textbf{State Prediction:} A predicted pose is formed by adding a stored global offset to the current raw pose from wheel odometry.
  \item \textbf{Measurement Prediction:} For each sensor, the expected distance to a wall is calculated using the predicted pose and the known map geometry.
  \item \textbf{Measurement Validation:} Each real measurement is compared to its prediction and classified using a rule-based filter (see Fig. \ref{fig:validation_cases}).
  \item \textbf{Geometric Correction:} For each valid measurement, a direct, closed-form correction for either the $x$ or $y$ axis is computed.
  \item \textbf{Correction Fusion & Update:} Corrections from multiple sensors are fused, and the global odometry offset is updated.
\end{enumerate}

\subsection{Geometric Correction}
For a sensor $i$ with world pose $(x_s, y_s)$ and orientation $\theta_s$, the intersection point with a vertical wall at $X_{\text{wall}}$ can be used to find the true $x$-position of the robot's center. As illustrated in Fig. \ref{fig:geometry}, this is an algebraic calculation:
\[
    x = X_{\text{wall}} - (d_i \cos(\theta_s) + x_{tf,i})
\]
A similar equation holds for deriving the $y$-position from a horizontal wall. This provides a direct correction without iteration.

% --- FIGURE PLACEHOLDER ---
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\columnwidth]{2SensorInverseKin.png}
    \caption{Geometric model for a single sensor. The sensor's ray, cast at angle $\theta_s$, intersects a vertical wall. The robot's true x-coordinate can be derived from the wall's known position $X_{\text{wall}}$ and the measured distance $d$.}
    \label{fig:geometry}
\end{figure}
% --------------------------

\subsection{Measurement Validation}
Robustness is achieved by filtering unreliable measurements. Each measurement is classified:
\begin{itemize}
  \item \texttt{VALID}: The measurement is consistent with the predicted distance and geometry.
  \item \texttt{BLOCKED}: Measured distance is significantly smaller than predicted, indicating an unmapped obstacle.
  \item \texttt{CORNER}: The sensor beam is aimed near a corner, where the intersecting wall is ambiguous.
  \item \texttt{ANGLE_INVALID}: The beam is nearly parallel to the wall, making the intersection point highly sensitive to noise.
  \item \texttt{SATURATED}: The sensor returns its maximum value, indicating no object was detected in range.
\end{itemize}
Only \texttt{VALID} measurements are passed to the correction stage.

% --- FIGURE PLACEHOLDER ---
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{SensorValidation.png}
    \caption{Illustration of measurement validation logic. (a) A valid measurement where the measured distance matches the prediction. (b) A corner case where the ray's intersection is ambiguous. (c) A blocked ray where an obstacle causes a short reading. These cases are filtered deterministically.}
    \label{fig:validation_cases}
\end{figure}
% --------------------------

\subsection{Correction Fusion}
If multiple sensors provide corrections for the same axis (e.g., front and back sensors hitting parallel walls), their results are averaged to reduce noise. If only one valid measurement is available, its correction is used directly. The final correction is applied to a global offset variable, which continuously aligns the free-drifting odometry frame with the global world frame.

\section{Complexity and Implementation}
\subsection{Computational Complexity}
The algorithm's computational cost per cycle is exceptionally low. For $N_s$ sensors, the process involves:
\begin{itemize}
    \item $N_s$ sensor pose transformations (trigonometry, additions).
    \item $N_s$ ray-intersection calculations (4 wall checks each).
    \item $N_s$ validation checks (comparisons).
    \item A small, constant number of operations for fusion.
\end{itemize}
The total complexity is therefore $O(N_s)$, with no dependence on the map size (beyond the 4 walls) and no iterative loops. This makes it highly predictable and suitable for real-time execution.

\subsection{Implementation on Microcontrollers}
The algorithm was implemented in C for an STM32 microcontroller. Key considerations were the use of fixed-point arithmetic where possible and look-up tables for trigonometric functions to reduce floating-point load. The code snippet below shows the core ray-intersection logic.

\begin{lstlisting}[language=C,caption={Core ray-wall intersection logic}]
// Simplified logic for finding minimum intersection distance
float t_min = INFINITY;
// Check intersection with vertical walls (x=0, x=W)
if (fabs(dx) > EPS) {
    float t = (0.0 - sensor_x) / dx; // Left wall
    if (t > 0 && is_within_y_bounds(sensor_y + t*dy)) t_min = fmin(t_min, t);
    t = (W - sensor_x) / dx;   // Right wall
    if (t > 0 && is_within_y_bounds(sensor_y + t*dy)) t_min = fmin(t_min, t);
}
// Check intersection with horizontal walls (y=0, y=L)
if (fabs(dy) > EPS) {
    float t = (0.0 - sensor_y) / dy; // Bottom wall
    if (t > 0 && is_within_x_bounds(sensor_x + t*dx)) t_min = fmin(t_min, t);
    t = (L - sensor_y) / dy;   // Top wall
    if (t > 0 && is_within_x_bounds(sensor_x + t*dx)) t_min = fmin(t_min, t);
}
expected_dist[i] = t_min;
\end{lstlisting}

\section{Evaluation Plan}
We propose a comprehensive plan to validate our algorithm's performance against ground truth and standard baselines.

\subsubsection{Metrics}
The primary metrics will be the Root Mean Square Error (RMSE) of the estimated pose $(x, y, \theta)$ relative to a motion capture system, and the CPU load on the target microcontroller.

\subsubsection{Baselines}
We will compare our method against:
\begin{itemize}
  \item \textbf{Raw Odometry}: To quantify the baseline drift.
  \item \textbf{EKF}: A standard Extended Kalman Filter fusing odometry, heading, and range data.
  \item \textbf{MCL}: A lightweight particle filter with a particle count tuned to be computationally comparable to our method.
\end{itemize}

\subsubsection{Test Scenarios}
The robot will execute several trajectories, including:
\begin{itemize}
    \item A 4m x 2m rectangular path to test performance along straight lines and at corners.
    \item A figure-eight trajectory to test performance during continuous heading changes.
    \item A "kidnapped robot" test where the robot is manually moved to assess recovery.
    \item Obstacle tests where objects are temporarily placed to block sensors.
\end{itemize}
Expected results are summarized in the placeholder Table \ref{tab:results} and Fig. \ref{fig:trajectory}.

% --- TABLE PLACEHOLDER ---
\begin{table}[t]
\centering
\caption{Placeholder for Quantitative Results Summary}
\label{tab:results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Method} & \textbf{RMSE x (cm)} & \textbf{RMSE y (cm)} & \textbf{RMSE $\theta$ (deg)} & \textbf{CPU Load (\%)} \\ \midrule
Odometry Only & [Fill In] & [Fill In] & [Fill In] & N/A \\
Our Method    & [Fill In] & [Fill In] & [Fill In] & [Fill In] \\
EKF           & [Fill In] & [Fill In] & [Fill In] & [Fill In] \\
MCL (Light)   & [Fill In] & [Fill In] & [Fill In] & [Fill In] \\ \bottomrule
\end{tabular}
\end{table}
% --------------------------

% --- FIGURE PLACEHOLDER ---
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\columnwidth]{ComparisonVisualizer.png}
    \caption{Example trajectory plot from a simulated run. The ground truth (ideal path) is compared against raw odometry (drifting) and the output of our proposed algorithm, which remains bounded.}
    \label{fig:trajectory}
\end{figure}
% --------------------------

\section{Discussion and Conclusion}
\subsection{Limitations and Future Work}
The primary limitation of our method is its reliance on a known, rectangular map. Extending the geometric engine to support general polygonal maps is a key direction for future work. This would involve replacing the analytic intersection formulas with a more general ray-casting algorithm, which may increase computational cost.

The algorithm is also sensitive to significant heading errors from the IMU. While the validation rules provide some robustness, large, uncorrected heading drift could lead to incorrect wall identifications. Future work could explore fusing corrections from multiple, non-parallel sensors to simultaneously solve for a small heading correction.

Finally, performance is critically dependent on accurate sensor calibration. An automated calibration routine to identify sensor poses and scale factors would greatly improve usability.

\subsection{Conclusion}
We have presented a deterministic, compAutationally lightweight localization algorithm for mobile robots in structured environments. By leveraging known geometry to create direct, algebraic corrections to odometry, our method provides a robust and efficient alternative to more complex probabilistic techniques. Its low, predictable computational footprint makes it ideal for embedded, real-time systems. The proposed evaluation will serve to quantify its performance benefits on physical hardware.

\section*{Acknowledgment}
% Acknowledge funding sources, colleagues, and other support here.
The authors thank the members of the MIT Tech Team for their support and the anonymous reviewers for their valuable feedback.

%
% BIBLIOGRAPHY
%
\begin{thebibliography}{99}

\bibitem{probrobot}
S. Thrun, W. Burgard, and D. Fox, \emph{Probabilistic Robotics}.\hskip 1em plus 0.5em minus 0.4em\relax MIT Press, 2005. [Online]. Available: \url{https://mitpress.mit.edu/books/probabilistic-robotics}

\bibitem{mcl}
F. Dellaert, D. Fox, W. Burgard, and S. Thrun, “Monte carlo localization for mobile robots,” in \emph{Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}, 1999, vol. 2, pp. 1322–1328. [Online]. Available: \url{http://www.cs.cmu.edu/~thrun/papers/thrun.mcl.html}

\bibitem{icp}
P. J. Besl and N. D. McKay, “A method for registration of 3-D shapes,” \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol. 14, no. 2, pp. 239–256, 1992. [Online]. Available: \url{https://ieeexplore.ieee.org/document/121791}

\bibitem{okane}
J. M. O'Kane and S. M. LaValle, “Visibility-based pursuit-evasion in a polygonal environment,” \emph{International Journal of Robotics Research}, vol. 26, no. 9, pp. 869–887, 2007. [Online]. Available: \url{https://journals.sagepub.com/doi/abs/10.1177/0278364907081394}

\bibitem{Smith1990}
R. Smith, M. Self, and P. Cheeseman, “Estimating uncertain spatial relationships in robotics,” in \emph{Autonomous Robot Vehicles}, I. J. Cox and G. T. Wilfong, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 1990, pp. 167–193. [Online]. Available: \url{https://ieeexplore.ieee.org/document/1087119}

\bibitem{Dellaert1999}
F. Dellaert, D. Fox, W. Burgard, and S. Thrun, “Monte Carlo Localization for Mobile Robots,” in \emph{Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}, 1999, vol. 2, pp. 1322–1328. [Online]. Available: \url{http://www.cs.cmu.edu/~thrun/papers/thrun.mcl.html}

\bibitem{Besl1992}
P. J. Besl and N. D. McKay, “A method for registration of 3-D shapes,” \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol. 14, no. 2, pp. 239–256, 1992. [Online]. Available: \url{https://ieeexplore.ieee.org/document/121791}

\bibitem{rangeopt}
\emph{Placeholder for Range Optimization Methods}, Online. [Note: Placeholder citation, specific reference to be added], 2023.

\bibitem{Siciliano2016}
B. Siciliano and O. Khatib, Eds., \emph{Springer Handbook of Robotics}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2016. [Online]. Available: \url{https://link.springer.com/book/10.1007/978-3-319-32552-1}

\bibitem{Choset2005}
H. Choset, \emph{Principles of Robot Motion: Theory, Algorithms, and Implementations}.\hskip 1em plus 0.5em minus 0.4em\relax MIT Press, 2005. [Online]. Available: \url{https://mitpress.mit.edu/books/principles-robot-motion}

\bibitem{Gutmann2002}
J. S. Gutmann and D. Fox, “A Hybrid Grid-Based, Feature-Based Approach for Mobile Robot Localization,” in \emph{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2002, vol. 3, pp. 2237–2242. [Online]. Available: \url{https://ieeexplore.ieee.org/document/1041699}

\bibitem{Leonard1991}
J. J. Leonard and H. F. Durrant-Whyte, “Mobile Robot Localization by Tracking Geometric Beacons,” \emph{IEEE Transactions on Robotics and Automation}, vol. 7, no. 3, pp. 376–382, 1991. [Online]. Available: \url{https://ieeexplore.ieee.org/document/88147}

\bibitem{Howard2002}
A. Howard, M. J. Matarić, and G. S. Sukhatme, “Relaxation on a Mesh: A Formalism for Generalized Execution of Sensor Fusion,” in \emph{Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2002, vol. 1, pp. 104–111. [Online]. Available: \url{https://ieeexplore.ieee.org/document/1041696}

\end{thebibliography}

\end{document}